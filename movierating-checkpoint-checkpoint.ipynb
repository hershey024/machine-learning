{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24282, 78)\n",
      "(24282, 78)\n",
      "(24999, 1)\n",
      "[[\"I loved this movie since I was 7 and I saw it on the opening day. It was so touching and beautiful. I strongly recommend seeing for all. It's a movie to watch with your family by far.<br /><br />My MPAA rating: PG-13 for thematic elements\"\n",
      "  ' prolonged scenes of disastor' ' nudity/sexuality and some language.'\n",
      "  ... nan nan 8]\n",
      " ['First things first' ' Edison Chen did a fantastic'\n",
      "  ' believable job as a Cambodian hit-man' ... nan nan 7]\n",
      " ['Once again'\n",
      "  ' I was browsing through the discount video bin and picked up this movie for $4.88. Fifty-percent of the time the movies I find in the bin are pure crap (I mean horrible beyond belief) but half the time they turn out to be surprisingly good. This movie is much better than I expected. I found it very engaging'\n",
      "  ' though it was obviously made by an amateur.<br /><br /> The direction is nothing special'\n",
      "  ... nan nan 8]\n",
      " ...\n",
      " ['After a cold sex scene' ' between Andy and Gina' ' in South America'\n",
      "  ... nan nan 10]\n",
      " ['A big surprise'\n",
      "  ' probably because I was expecting it to suck. The reviews were pretty dismissive of it'\n",
      "  ' even though they all seemed to agree that the concept was golden: a man finds out his new girlfriend is a super hero'\n",
      "  ... nan nan 10]\n",
      " ['Warning: contains a spoiler. Corny plot and in many cases terrible acting. Fontaine is great'\n",
      "  ' but some others' ' particularly Richard Ney' ... nan nan 10]]\n",
      "(24282, 79)\n",
      "[\"I loved this movie since I was 7 and I saw it on the opening day. It was so touching and beautiful. I strongly recommend seeing for all. It's a movie to watch with your family by far.<br /><br />My MPAA rating: PG-13 for thematic elements\"\n",
      " ' prolonged scenes of disastor' ' nudity/sexuality and some language.' 8\n",
      " 'First things first' ' Edison Chen did a fantastic'\n",
      " ' believable job as a Cambodian hit-man'\n",
      " ' born and bred in the dumps and a gladiatorial ring'\n",
      " ' where he honed his craft of savage battery in order to survive'\n",
      " ' living on the mantra of kill or be killed. In a role that had little dialogue'\n",
      " ' or at least a few lines in Cambodian/Thai'\n",
      " ' his performance is compelling'\n",
      " ' probably what should have been in the Jet Li vehicle Danny the Dog'\n",
      " ' where a man is bred for the sole purpose of fighting'\n",
      " \" and on someone else's leash.<br /><br />Like Danny the Dog\"\n",
      " ' the much talked about bare knuckle fight sequences are not choreographed stylistically'\n",
      " ' but rather designed as normal' ' brutal fisticuffs'\n",
      " \" where everything goes. This probably brought a sense of realism and grit when you see the characters slug it out at each other's throats\"\n",
      " \" in defending their own lives while taking it away from others. It's a grim\"\n",
      " ' gritty and dark movie both literally and figuratively'\n",
      " ' and this sets it apart from the usual run off the mill cop thriller production.<br /><br />Edison plays a hired gun from Cambodia'\n",
      " ' who becomes a fugitive in Hong Kong'\n",
      " ' on the run from the cops as his pickup had gone awry. Leading the chase is the team led by Cheung Siu-Fai'\n",
      " ' who has to contend with maverick member Inspector Ti (Sam Lee)'\n",
      " \" who's inclusion and acceptance in the team had to do with the sins of his father. So begins a cat and mouse game in the dark shades and shadows of the seedier looking side of Hong Kong.<br /><br />The story itself works on multiple levels\"\n",
      " ' especially in the character studies of the hit-man'\n",
      " ' and the cop. On opposite sides of the law'\n",
      " ' we see within each character not the black and white'\n",
      " ' but the shades of grey. With the hit-man'\n",
      " ' we see his caring side when he got hooked up and developed feelings of love for a girl (Pei Pei)'\n",
      " ' bringing about a sense of maturity' ' tenderness'\n",
      " ' and revealing a heart of gold. The cop'\n",
      " ' with questionable tactics and attitudes'\n",
      " ' makes you wonder how one would buckle when willing to do anything it takes to get the job done. There are many interesting moments of moral questioning'\n",
      " ' on how anti-hero' \" despicable strategies are adopted. You'll ask\"\n",
      " ' what makes a man' ' and what makes a beast'\n",
      " ' and if we have the tendency to switch sides depending on circumstances - do we have that dark inner streak in all of us'\n",
      " ' transforming from man to dog'\n",
      " ' and dog to man? Dog Bite Dog grips you from the start and never lets go until the end'\n",
      " ' though there are points mid way through that seemed to drag'\n",
      " ' especially on its tender moments'\n",
      " ' and it suffered too from not knowing when to end. If I should pick a favourite scene'\n",
      " ' then it must be the one in the market food centre - extremely well controlled and delivered'\n",
      " ' a suspenseful edge of your seat moment. Listen out for the musical score too'\n",
      " \" and you're not dreaming if you hear growls of dogs.<br /><br />Highly recommended\"\n",
      " \" especially if you think that you've seen about almost everything from the cop thriller genre.\"\n",
      " 7 'Once again'\n",
      " ' I was browsing through the discount video bin and picked up this movie for $4.88. Fifty-percent of the time the movies I find in the bin are pure crap (I mean horrible beyond belief) but half the time they turn out to be surprisingly good. This movie is much better than I expected. I found it very engaging'\n",
      " ' though it was obviously made by an amateur.<br /><br /> The direction is nothing special'\n",
      " ' but the story is intriguing with some good thrills. I expected it to be more of a comedy'\n",
      " \" but I wasn't too disappointed.<br /><br /> For a thriller\"\n",
      " \" this movie is surprisingly good-natured. There's no bloody violence\"\n",
      " ' no profanity' ' no nudity' ' no sex. Usually'\n",
      " ' these movies require all four of those elements. The PG rating is well-deserved--not like \"Sixteen Candles\" where the \"f\" word is used twice and there\\'s a brief gratuitous nude scene.<br /><br /> I just wish the romance between Corey Haim and his love interest could\\'ve been developed more. The film does tend to be plot-heavy'\n",
      " ' and the potentially good subplots are pushed off to the side. Instead of developing a chemistry between the two of them'\n",
      " ' we end up watching a careless three-minute montage of them on their romantic endeavors. They end up kissing at the end'\n",
      " ' but there\\'s so little chemistry that it seems forced.<br /><br />\"The Dream Machine\" is no gem'\n",
      " \" but it's good\"\n",
      " \" clean entertainment. It's quite forgettable--especially with a cast of unknowns\"\n",
      " \" except for Haim--but it's also much better than you'd expect.<br /><br /> My score: 7 (out of 10)\"\n",
      " 8 'This is a gem'\n",
      " ' a real piece of Americana for all that this implies. If you are self programed to resist \"life-afirming\" stories'\n",
      " ' just stay away and leave the pleasure to the rest of us who still believe. And what makes the frosting on the cake truly delectable is that it is fact based on a real rags to riches story'\n",
      " ' no need to nit-pick what details were changed to make a compact story. Chris Cooper is one of the greatest living actors'\n",
      " ' and the complex' ' self-conflicted'\n",
      " ' bottom-line good at the core father he portrayed could only be pulled off successfully by someone with his skill and insight. The simple minded comments'\n",
      " ' refusing to accept a father who tries to lay down the law all the while sensing that he may possibly be off-track'\n",
      " ' expose the limitation of the commentator'\n",
      " ' not the writers or the acting. This is not for the cynical'\n",
      " ' or the simple minded.' 8\n",
      " 'While I had wanted to se this film since the first time I watched the trailer'\n",
      " ' I was in for a deep surprise with this film. While some of the elements and actions of the characters seemed a little too \\x91cartoonish'\n",
      " \"' the dark nature of the film really makes this a much different experience. Instead of the feel-good-happy-story\"\n",
      " ' this film takes you in another direction that proves to be uplifting'\n",
      " \" but also disturbing. Most kids won't understand some of the darker moments in the film\"\n",
      " ' which makes this film rather watchable for adults. I was also impressed with the cinematography'\n",
      " ' using animation and digital animation to create a seamless network of pans and tilts. The musical score was once again solid'\n",
      " ' proving Hans Zimmer is the go-to guy when it comes to animated scores'\n",
      " \" and I never thought I would say I actually enjoyed Brian Adams' music.\"\n",
      " 8\n",
      " 'Some films manage to survive almost on originality alone - \"Wonderland\" is certainly one of those films. The script manages to throw everything into a near-fever pitch'\n",
      " ' but without making it incoherent. The speed of this thriller is not to chosen to cover up a weak script'\n",
      " ' but rather to accurately reflect the drug-addled reality.<br /><br />As director'\n",
      " ' James Cox as a very peculiar way of working his actors. Most of the characters are perpetually on edge'\n",
      " \" and often because they're rather quite ugly personalities. Val Kilmer has described John Holmes to be a hustler\"\n",
      " ' able to manipulate and control. No offense to Kilmer'\n",
      " ' but his version of Holmes seems only able to control the drastically weak-minded. Nonetheless'\n",
      " ' it\\'s a stunning performance. Comparing this to Kilmer\\'s more \\'Hollywood\\' roles like in \"The Saint\" it seems to prove he is far more at home in gritty indie flicks.<br /><br />The actors are the main force holding all together. There are various little performances that stand out - especially the women. Carrie Fisher'\n",
      " ' Kate Bosworth'\n",
      " ' and Lisa Kudrow all have limited screen time next to their male counterparts']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1.Data Preparation\n",
    "\n",
    "X_train= pd.read_csv(r'C:/Users/hershey/Desktop/ML/movieratingpred/imdb_trainX.csv', encoding='UTF-8',names = list(range(0,78)))\n",
    "Y_train= pd.read_csv(r'C:/Users/hershey/Desktop/ML/movieratingpred/imdb_trainY.csv', encoding='UTF-8')\n",
    "X_test= pd.read_csv(r'C:/Users/hershey/Desktop/ML/movieratingpred/imdb_testX.csv', encoding='UTF-8',names = list(range(0,78)))\n",
    "Y_test= pd.read_csv(r'C:/Users/hershey/Desktop/ML/movieratingpred/imdb_testY.csv', encoding='UTF-8')\n",
    "\n",
    "   \n",
    "X_tr= X_train.values \n",
    "X_tst= X_test.values\n",
    "Y_tr= Y_train.values    \n",
    "Y_tst= Y_test.values\n",
    "\n",
    "print(X_tr.shape)\n",
    "#X_tr= X_tr[pd.notnull(X_tr)]\n",
    "#Y_tr= Y_tr[pd.notnull(Y_tr)]\n",
    "#for i in range(0,X_tr.shape[0]):\n",
    "    #for j in range(0, X_tr.shape[1]):\n",
    "        #if pd.isnull(X_tr.any()) :\n",
    "            #continue\n",
    "        #else:\n",
    "            #X_trn= X_tr\n",
    "            \n",
    "print(X_tr.shape)\n",
    "print(Y_tr.shape)\n",
    "X= np.hstack((X_tr,Y_tr[0:24282]))\n",
    "print(X[:100])\n",
    "print(X.shape)\n",
    "X= X[pd.notnull(X)]\n",
    "X= np.array(X)\n",
    "print(X[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-890231835686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mcln_x_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mcln_y_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mcln_x_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtextinfextractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcln_x_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mcln_y_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtextinfextractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-890231835686>\u001b[0m in \u001b[0;36mtextinfextractor\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 2. Cleaning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtextinfextractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdoc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#lower())\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0msw\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0museful_words\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msw\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \"\"\"\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[0;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m     94\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;31m# Standard word tokenizer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \"\"\"\n\u001b[1;32m-> 1241\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m         \"\"\"\n\u001b[1;32m-> 1291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m         \"\"\"\n\u001b[1;32m-> 1291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1281\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \"\"\"\n\u001b[0;32m   1321\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(it)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \"\"\"\n\u001b[0;32m    312\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m     \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_tok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": [
    "# 2. Cleaning\n",
    "def textinfextractor(doc):\n",
    "    doc=word_tokenize(doc)#lower())\n",
    "    sw= set(stopwords.words('english'))\n",
    "    useful_words= [w for w in doc if w not in sw ]\n",
    "    useful_words= np.asarray(useful_words)\n",
    "    m=useful_words.shape[0]\n",
    "    print(useful_words.shape[0])\n",
    "    final= []  \n",
    "    for i in range (m):\n",
    "        ss= PorterStemmer() \n",
    "        k=ss.stem(useful_words[i])\n",
    "        final.append(k)\n",
    "    j=[]\n",
    "    final= np.asarray(final)\n",
    "    k= final.shape[0]\n",
    "    for i in range (k):\n",
    "        if final[i] == (\":\"):\n",
    "            continue\n",
    "        elif final[i] == (\"br\"):\n",
    "            continue\n",
    "        elif final[i] == (\"/\"):\n",
    "            continue   \n",
    "        elif final[i] == (\",\"):\n",
    "            continue\n",
    "        elif final[i] == (\"<\"):\n",
    "            continue\n",
    "        elif final[i] == (\">\"):\n",
    "            continue\n",
    "        elif final[i] == (\".\"):\n",
    "            continue\n",
    "        else:\n",
    "            j.append(final[i])\n",
    "    return j\n",
    "\n",
    "\n",
    "cln_x_train=[]\n",
    "cln_y_train=[]\n",
    "cln_x_train=textinfextractor(X)\n",
    "print(cln_x_train[:100])\n",
    "cln_y_train=textinfextractor(Y_tr)\n",
    "print(cln_y_train[:100])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
