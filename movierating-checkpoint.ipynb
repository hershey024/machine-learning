{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['10\\n', '8\\n', '7\\n', '8\\n', '8\\n', '8\\n', '10\\n', '9\\n', '10\\n', '8\\n', '8\\n', '8\\n', '10\\n', '8\\n', '8\\n', '8\\n', '9\\n', '10\\n', '7\\n', '7\\n', '8\\n', '7\\n', '8\\n', '9\\n', '8\\n', '7\\n', '10\\n', '10\\n', '7\\n', '9\\n', '9\\n', '7\\n', '10\\n', '10\\n', '10\\n', '10\\n', '7\\n', '9\\n', '10\\n', '9\\n', '10\\n', '9\\n', '10\\n', '8\\n']\n",
      "[\"not really sure what to make of this movie. very weird, very artsy. not the kind of movie you watch because it has a compelling plot or characters. more like the kind of movie that you can't stop watching because of the horrifically fascinating things happening on screen. although, the first time my wife watched this she couldn't make it all the way through... too disturbing for her. runs a bit long, but nonetheless a worthwhile viewing for those interested in very dark movies.\\n\"]\n",
      "['7\\n', '10\\n', '10\\n', '10\\n', '8\\n', '10\\n', '10\\n', '9\\n', '9\\n', '10\\n', '7\\n', '8\\n', '7\\n', '7\\n', '9\\n', '9\\n', '9\\n', '9\\n', '10\\n', '8\\n', '9\\n', '7\\n', '10\\n', '10\\n', '8\\n', '7\\n', '7\\n', '10\\n', '10\\n', '7\\n', '8\\n', '10\\n', '10\\n', '10\\n', '10\\n', '10\\n', '7\\n', '7\\n', '8\\n', '8\\n', '7\\n', '9\\n', '10\\n']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1.Data Preparation\n",
    "\n",
    "with open(r'C:\\Users\\hershey\\Desktop\\ML\\imdb_trainX.txt',mode= 'r', encoding= 'UTF-8') as trainx:\n",
    "    print(trainx.readlines(100))\n",
    "with open(r'C:\\Users\\hershey\\Desktop\\ML\\imdb_trainY.txt',mode= 'r', encoding= 'UTF-8') as trainy:\n",
    "    print(trainy.readlines(100))\n",
    "\n",
    "with open(r'C:\\Users\\hershey\\Desktop\\ML\\imdb_testX.txt',mode= 'r', encoding= 'UTF-8') as testx:\n",
    "    print(testx.readlines(100))\n",
    "with open(r'C:\\Users\\hershey\\Desktop\\ML\\imdb_testY.txt',mode= 'r', encoding= 'UTF-8') as testy:\n",
    "    print(testy.readlines(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# 2. Cleaning\n",
    "def textinfextractor(file):\n",
    "    doc=file.read()  #.decode('utf-8')\n",
    "    print(type(doc))\n",
    "    doc=word_tokenize(doc) #lower())\n",
    "    sw= set(stopwords.words('english'))\n",
    "    useful_words= [w for w in doc if w not in sw ]\n",
    "    useful_words= np.asarray(useful_words)\n",
    "    m=useful_words.shape[0]\n",
    "    final=   []  # np.array((m,))\n",
    "    for i in range (m):\n",
    "        ss= PorterStemmer() \n",
    "        k=ss.stem(useful_words[i])\n",
    "        final.append(k)\n",
    "    return final\n",
    "with open(r'C:\\Users\\hershey\\Desktop\\ML\\imdb_trainX.txt',mode= 'r', encoding= 'UTF-8') as trainx:\n",
    "    textinfextractor(trainx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
